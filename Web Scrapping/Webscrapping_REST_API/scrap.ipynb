{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas requests BeautifulSoup4 \n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "base_url = \"https://www.consumeraffairs.com/food/dominos.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store all review\n",
    "all_pages_reviews =[]\n",
    "\n",
    "# Create a Scraper function\n",
    "def scraper():\n",
    "\t# Web scraping - fetching the reviews from the webpage using BeautifulSoup\n",
    "\n",
    "\t# loop through a range of page numbers \n",
    "\tfor i in range(1,6): # fetching reviews from five pages\n",
    "\n",
    "\t\t# Creating an empty list to store the reviews of each page\n",
    "\t\tpagewise_reviews = [] \n",
    "\n",
    "\t\t# Query parameter\n",
    "\t\tquery_parameter = \"?page=\"+str(i)\n",
    "\n",
    "\t\t# Constructing the URL\n",
    "\t\turl = base_url + query_parameter\n",
    "\t\t\n",
    "\t\t# Send HTTP request to the URL\n",
    "\t\tresponse = requests.get(url)\n",
    "\n",
    "\t\t# Create a soup object and parse the HTML page\n",
    "\t\tsoup = bs(response.content, 'html.parser') \n",
    "\n",
    "\t\t# Finding all the elements having reviews using class attribute\n",
    "\t\trev_div = soup.findAll(\"div\",attrs={\"class\",\"rvw-bd\"}) \n",
    "\n",
    "\t\t# loop through all the divs and append \n",
    "\t\tfor j in range(len(rev_div)):\n",
    "\t\t\t# finding all the p tags to fetch only the review text\n",
    "\t\t\tpagewise_reviews.append(rev_div[j].find(\"p\").text)\n",
    "\n",
    "\t\t# writing all the reviews into a list\n",
    "\t\tfor k in range(len(pagewise_reviews)):\n",
    "\t\t\tall_pages_reviews.append(pagewise_reviews[k]) \n",
    "\n",
    "\t# return the final list of reviews\n",
    "\treturn all_pages_reviews\n",
    "\n",
    "# Driver code\n",
    "reviews = scraper()\n",
    "\n",
    "# Storing in a dataframe\n",
    "i = range(1, len(reviews)+1)\n",
    "reviews_df = pd.DataFrame({'review':reviews}, index=i)\n",
    "\n",
    "# Writing to a text file\n",
    "reviews_df.to_csv('reviews.txt', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6763ba6110e050d0e6d4dc5757df4d9377869df6777c500c615f7546a6ecc95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
